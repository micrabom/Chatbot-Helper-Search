{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Evaluation Dataset\n",
    "\n",
    "This Notebook generates a jsonl file that will be used to evaluate the efficacy of a prompt that is designed to extract long-term memories from a message.\n",
    "\n",
    "For instance, the following sentence:\n",
    "\n",
    "- I work long hours during the week, so having a meal plan that is quick and easy to prepare is crucial for me.\n",
    "\n",
    "Should be converted into a memory:\n",
    "\n",
    "- Works long hours\n",
    "- Meal plans should be quick and easy\n",
    "\n",
    "In order to evaluate our prompt, we will be generating the following:\n",
    "\n",
    "- Inputs: we will generate a series of possible messages that a user would share with the AI about meal planning\n",
    "- Existing memories: to test for each input, since we will either create new memories, update old memories, delete old memories, or do nothing depending on the existing memories\n",
    "- Expected output: the output we expect based on the input and existing memories, so that we can test if our output matches expected output\n",
    "- Bad output: an exmaple of output we would not expect based on the input and existing memories, to test the systemâ€™s ability to discriminate between correct and incorrect outputs\n",
    "\n",
    "Here is an example that we will be generating:\n",
    "\n",
    "{\n",
    "    \"input\": \"I work long hours during the week, so having a meal plan that is quick and easy to prepare is crucial for me.\", \n",
    "    \"memories\": [\"Meal plan needs to be slow and difficult to prepare\"], \n",
    "    \"desired_response\": [{\"knowledge\": \"Meal plan needs to be quick and easy to prepare\", \"category\": \"Attribute\", \"action\": \"Update\", \"knowledge_old\": \"Meal plan needs to be slow and difficult to prepare\"}, {\"knowledge\": \"Works long hours during the week\", \"category\": \"Attribute\", \"action\": \"Create\"}],\n",
    "    \"bad_response\": [{\"knowledge\": \"Meal plan needs to be elaborate and time-consuming to prepare\", \"category\": \"Attribute\", \"action\": \"Update\", \"knowledge_old\": \"Meal plan needs to be slow and difficult to prepare\"}, {\"knowledge\": \"Works long hours during the week\", \"category\": \"Like\", \"action\": \"Create\"}]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install openai==1.12.0 langchain==0.1.6 langchain_openai==0.0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load .env file\n",
    "load_dotenv('../.env')\n",
    "\n",
    "# Set model variables\n",
    "OPENAI_BASE_URL = \"https://api.openai.com/v1\"\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "OPENAI_ORGANIZATION = os.getenv(\"OPENAI_ORGANIZATION\")\n",
    "\n",
    "LANGCHAIN_TRACING_V2=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Run class\n",
    "This will help us manage our iterative creation of run data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "class Run:\n",
    "    def __init__(\n",
    "        self,\n",
    "        input,\n",
    "        desired_response=\"\",\n",
    "        bad_response=\"\",\n",
    "        memories=[],\n",
    "        desired_assistant_message=\"\",\n",
    "    ):\n",
    "        self.input = input\n",
    "        self.memories = memories\n",
    "        self.desired_response = desired_response\n",
    "        self.bad_response = bad_response\n",
    "        self.desired_assistant_message = desired_assistant_message\n",
    "\n",
    "    def update_memories(self, new_memories):\n",
    "        self.memories = self.extract_knowledge(new_memories)\n",
    "\n",
    "    def update_desired_response(self, response):\n",
    "        self.desired_response = self.extract_arguments(response)\n",
    "\n",
    "        function_call = response[\"tool_calls\"][0][\"function\"]\n",
    "\n",
    "        self.desired_assistant_message = {\n",
    "            \"role\": \"assistant\",\n",
    "            \"function_call\": {\n",
    "                \"name\": function_call[\"name\"],\n",
    "                \"arguments\": function_call[\"arguments\"],\n",
    "            },\n",
    "        }\n",
    "\n",
    "    def update_bad_response(self, response):\n",
    "        self.desired_response = self.extract_arguments(response)\n",
    "\n",
    "    def extract_arguments(self, data):\n",
    "        arguments_list = []\n",
    "\n",
    "        # Check if data is a dictionary and contains the key 'tool_calls'\n",
    "        if isinstance(data, dict) and \"tool_calls\" in data:\n",
    "            for tool_call in data[\"tool_calls\"]:\n",
    "                # Extracting the 'arguments' from the tool_call\n",
    "                function_info = tool_call.get(\"function\", {})\n",
    "                arguments = function_info.get(\"arguments\", \"\")\n",
    "\n",
    "                # If arguments is a string, attempt to parse it as JSON\n",
    "                if isinstance(arguments, str):\n",
    "                    try:\n",
    "                        arguments_json = json.loads(arguments)\n",
    "                        arguments_list.append(arguments_json)\n",
    "                    except json.JSONDecodeError:\n",
    "                        print(\"Error decoding JSON from arguments:\", arguments)\n",
    "\n",
    "        return arguments_list\n",
    "\n",
    "    def extract_knowledge(self, memories):\n",
    "        knowledge_list = []\n",
    "        if \"tool_calls\" in memories and isinstance(memories[\"tool_calls\"], list):\n",
    "            for item in memories[\"tool_calls\"]:\n",
    "                function = item.get(\"function\", {})\n",
    "                arguments = function.get(\"arguments\", \"\")\n",
    "\n",
    "                try:\n",
    "                    arguments_json = json.loads(arguments)\n",
    "                    knowledge = arguments_json.get(\"knowledge\", \"\")\n",
    "                    if knowledge:\n",
    "                        knowledge_list.append(knowledge)\n",
    "                except json.JSONDecodeError:\n",
    "                    print(\"Error decoding JSON from arguments:\", arguments)\n",
    "        return knowledge_list\n",
    "\n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            \"input\": self.input,\n",
    "            \"memories\": self.memories,\n",
    "            \"desired_response\": self.desired_response,\n",
    "            \"bad_response\": self.bad_response,\n",
    "            \"desired_assistant_message\": self.desired_assistant_message\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple test to confirm our setup is correct\n",
    "run = Run(input=\"Your input data\")\n",
    "run.update_memories(\n",
    "    {\n",
    "        \"tool_calls\": [\n",
    "            {\n",
    "                \"index\": 0,\n",
    "                \"id\": \"call_NqdC7z7UBDUIRjZ8lQbTNRkr\",\n",
    "                \"function\": {\n",
    "                    \"arguments\": '{\"knowledge\":\"I don\\'t eat fish\",\"category\":\"Dislike\",\"action\":\"Create\"}',\n",
    "                    \"name\": \"Knowledge_Modifier\",\n",
    "                },\n",
    "                \"type\": \"function\",\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_FILE_PATH = \"./data/eval_dataset.jsonl\"\n",
    "FINETUNE_FILE_PATH = \"./data/finetune_dataset.jsonl\"\n",
    "\n",
    "NUM_RUNS = 10  # Adjust the number of runs as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "\n",
    "class Category(str, Enum):\n",
    "    Food_Allergy = \"Allergy\"\n",
    "    Food_Like = \"Like\"\n",
    "    Food_Dislike = \"Dislike\"\n",
    "    Family_Attribute = \"Attribute\"\n",
    "\n",
    "\n",
    "class Action(str, Enum):\n",
    "    Create = \"Create\"\n",
    "    Update = \"Update\"\n",
    "    Delete = \"Delete\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Create the input text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the chain for generating inputs\n",
    "\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "SYSTEM_TEMPLATE_GENERATE_INPUT_TEXT = \"\"\"\n",
    "You are a person who is trying to meal-plan for a week.\n",
    "\n",
    "Before responding, come up with a persona, backstory, and goal for the person you are helping:\n",
    "\n",
    "- First, come up with your persona: are you a mother, father, boyfriend, wife, single adult? Do you have kids? How many people are your family?\n",
    "- Second, come up with a backstory: are you a busy professional? A stay-at-home parent? A college student?\n",
    "- Third, come up with a goal: are you trying to eat healthier? Save money? Save time?\n",
    "\n",
    "Now that you have identified your persona, imagine you are in the middle of meal-planning and someone just asked you the following question:\n",
    "\n",
    "{question}\n",
    "\n",
    "Answer the question in a way that a person with your exact backstory might if it was in the middle of a long conversation. You might simply be answering the question, but you may also be referencing something from earlier in the conversation or even providing extra context to explain your answer.\n",
    "\n",
    "In general, your answers should be pretty short (1 or 2 sentences).\n",
    "\n",
    "Just answer the question, don't share the persona, backstory, or goal you came up with. We will use that information to help guide the AI to give you a better response.\n",
    "\n",
    "Your response should only contain 1 key piece of information. For example \"I like X food\" instead of \"I like X and Y foods\", but it should exist within a 1 or 2 sentence response. Your goal is to help train and evaluate how good an AI is at extracting this bit of information from a conversation, so don't be way too obvious about your response.\n",
    "\n",
    "Be super imaginative with your answers. Don't just provide a boring answer. This will help the AI learn to be more creative and interesting in its responses.\n",
    "\n",
    "I will reward you if you provide an answer I've never seen before.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Get the prompt to use - you can modify this!\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessagePromptTemplate.from_template(SYSTEM_TEMPLATE_GENERATE_INPUT_TEXT),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Choose the LLM that will drive the agent\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo-0125\",\n",
    "    temperature=1.0,\n",
    ")\n",
    "\n",
    "generate_eval_runnable = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 10 runs to eval_dataset.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Generate NUM_RUNS inputs and save them to a JSONL file\n",
    "\n",
    "import json\n",
    "\n",
    "# Questions for the input\n",
    "QUESTION_1 = \"Do you have any dietary restrictions?\"\n",
    "QUESTION_2 = \"What kind of food do you like?\"\n",
    "QUESTION_3 = \"What should I know about you that would make your meal plan more helpful every week?\"\n",
    "\n",
    "runs = []\n",
    "\n",
    "for i in range(NUM_RUNS):\n",
    "    # Randomly select one of the questions\n",
    "    if i % 3 == 0:\n",
    "        question_input = {\"question\": QUESTION_1}\n",
    "    elif i % 3 == 1:\n",
    "        question_input = {\"question\": QUESTION_2}\n",
    "    else:\n",
    "        question_input = {\"question\": QUESTION_3}\n",
    "\n",
    "    # Assuming generate_eval_runnable.invoke returns a response with a .content attribute\n",
    "    response = generate_eval_runnable.invoke(question_input)\n",
    "\n",
    "    # Create a Run instance and append it to the runs list\n",
    "    run = Run(input=response.content)\n",
    "    runs.append(run.to_dict())\n",
    "\n",
    "# Save the runs to a JSONL file\n",
    "with open(EVAL_FILE_PATH, \"w\") as outfile:\n",
    "    for run in runs:\n",
    "        json.dump(run, outfile)\n",
    "        outfile.write(\"\\n\")\n",
    "\n",
    "print(f\"Saved {len(runs)} runs to {EVAL_FILE_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Generate memories for each input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the tool for extracting memories\n",
    "\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langchain.tools import StructuredTool\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "class AddKnowledge(BaseModel):\n",
    "    knowledge: str = Field(\n",
    "        ...,\n",
    "        description=\"Condensed bit of knowledge to be saved for future reference in the format [person] [fact] (e.g. Husband doesn't like tuna, I am allergic to shellfish, etc)\",\n",
    "    )\n",
    "    knowledge_old: Optional[str] = Field(\n",
    "        None,\n",
    "        description=\"If updating or deleting record, the complete, exact phrase that needs to be modified\",\n",
    "    )\n",
    "    category: Category = Field(\n",
    "        ..., description=\"Category that this knowledge belongs to\"\n",
    "    )\n",
    "    action: Action = Field(\n",
    "        ...,\n",
    "        description=\"Whether this knowledge is adding a new record, updating a record, or deleting a record\",\n",
    "    )\n",
    "\n",
    "\n",
    "def handle_action(\n",
    "    knowledge: str,\n",
    "    category: str,\n",
    "    action: str,\n",
    "    knowledge_old: str = \"\",\n",
    ") -> dict:\n",
    "    print(\"Handling Knowledge: \", knowledge, knowledge_old, category, action)\n",
    "\n",
    "\n",
    "knowledge_modifier = StructuredTool.from_function(\n",
    "    func=handle_action,\n",
    "    name=\"Knowledge_Modifier\",\n",
    "    description=\"Add, update, or delete a bit of knowledge\",\n",
    "    args_schema=AddKnowledge,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the chain for extracting memories\n",
    "\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    ")\n",
    "from langchain_core.utils.function_calling import convert_to_openai_function\n",
    "\n",
    "SYSTEM_PROMPT_EXPECTED_RESPONSE = \"\"\"\n",
    "You are a supervisor managing a team of knowledge eperts.\n",
    "\n",
    "Your team's job is to create a perfect knowledge base about a family's dining habits to assist in highly customized meal planning.\n",
    "\n",
    "The knowledge base should ultimately consist of many discrete pieces of information that add up to a rich persona (e.g. I like pasta; I am allergic to shellfish; I don't eat mussels; I live in Austin, Texas; I have a husband and 2 children aged 5 and 7).\n",
    "\n",
    "Every time you receive a message, you will evaluate if it has any information worth recording in the knowledge base.\n",
    "\n",
    "A message may contain multiple pieces of information that should be saved separately.\n",
    "\n",
    "You are only interested in the following categories of information:\n",
    "\n",
    "1. The family's food allergies (for example: a dairy or soy allergy) - These are important to know because they can be life-threatening. Only log something as an allergy if you are certain it is an allergy and not just a dislike.\n",
    "2. Foods the family likes (for example: likes pasta) - These are important to know because they can help you plan meals, but are not life-threatening.\n",
    "3. Foods the family dislikes (for example: doesn't eat mussels or rarely eats beef) - These are important to know because they can help you plan meals, but are not life-threatening.\n",
    "4. Attributes about the family that may impact weekly meal planning (for example: lives in Austin, has a husband and 2 children, has a garden, likes big lunches, etc.)\n",
    "\n",
    "When you receive a message, you perform a sequence of steps consisting of:\n",
    "\n",
    "1. Analyze the most recent Human message for information. You will see multiple messages for context, but we are only looking for new information in the most recent message.\n",
    "2. Compare this to the knowledge you already have.\n",
    "3. Determine if this is new knowledge, an update to old knowledge that now needs to change, or should result in deleting information that is not correct. It's possible that a food you previously wrote as a dislike might now be a like, or that a family member who previously liked a food now dislikes it - those examples would require an update.\n",
    "\n",
    "Here are the existing bits of information that we have about the family.\n",
    "\n",
    "```\n",
    "{memories}\n",
    "```\n",
    "\n",
    "Call the right tools to save the information, then respond with DONE. If you identiy multiple pieces of information, call everything at once. You only have one chance to call tools.\n",
    "\n",
    "I will tip you $20 if you are perfect, and I will fine you $40 if you miss any important information or change any incorrect information.\n",
    "\n",
    "Take a deep breath, think step by step, and then analyze the following message:\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessagePromptTemplate.from_template(SYSTEM_PROMPT_EXPECTED_RESPONSE),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Choose the LLM that will drive the agent\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo-0125\",\n",
    "    # model=\"gpt-4-0125-preview\",\n",
    "    streaming=True,\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "# Create the tools to bind to the model\n",
    "agent_tools = [knowledge_modifier]\n",
    "tools = [convert_to_openai_function(t) for t in agent_tools]\n",
    "\n",
    "knowledge_master_runnable = prompt | llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the chain for mutating a memory\n",
    "\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "SYSTEM_TEMPLATE_MUTATE_MEMORY = \"\"\"\n",
    "Your job is to mutate a string of text to change the meaning of it by only changing or modifying a single word.\n",
    "\n",
    "This may take a few possible paths:\n",
    "- You might make the meaning the opposite of the original meaning\n",
    "- You might change the intensity of the meaning (from like to love, or from dislike to hate)\n",
    "- You might take an allergy and just make it a dislike, or vice versa\n",
    "\n",
    "But you will not change the subject or object in the sentence, just the relationship between them.\n",
    "\n",
    "Here is the sentence to modify: \n",
    "\n",
    "```\n",
    "{memory}\n",
    "```\n",
    "\n",
    "Now return a string that contains the modified sentence and nothing else.\n",
    "\"\"\"\n",
    "\n",
    "# Get the prompt to use - you can modify this!\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessagePromptTemplate.from_template(SYSTEM_TEMPLATE_MUTATE_MEMORY),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Choose the LLM that will drive the agent\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo-0125\",\n",
    "    temperature=1.0,\n",
    ")\n",
    "\n",
    "mutate_memory_runnable = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through each input and generate memories for each\n",
    "\n",
    "import json\n",
    "from langchain_core.messages import HumanMessage\n",
    "import random\n",
    "\n",
    "\n",
    "def generate_memories_for_eval_dataset(file_name):\n",
    "    updated_runs = []\n",
    "\n",
    "    with open(file_name, \"r\") as infile:\n",
    "        lines = infile.readlines()\n",
    "        data_entries = [json.loads(line.strip()) for line in lines]\n",
    "\n",
    "    for index, data in enumerate(data_entries):\n",
    "        if \"input\" in data:\n",
    "            if index > 2:\n",
    "                choice = random.randint(1, 4)\n",
    "            else:\n",
    "                choice = random.randint(1, 3)\n",
    "            # For each index, we either want to:\n",
    "            # 1. Generate accurate memories\n",
    "            # 2. Generate accurate memories and then mutate one of them\n",
    "            # 3. Generate no memories\n",
    "            # 4. Generate memories from a combination of 1 or 2 other entries\n",
    "            if choice < 3:\n",
    "                # Create memory from input\n",
    "                messages = [HumanMessage(content=data.get(\"input\"))]\n",
    "                response = knowledge_master_runnable.invoke(\n",
    "                    {\"messages\": messages, \"memories\": []}\n",
    "                )\n",
    "\n",
    "                run_instance = Run(input=data.get(\"input\"))\n",
    "\n",
    "                run_instance.update_memories(response.additional_kwargs)\n",
    "\n",
    "                # Some of the time, we want to create a mutated version of that memory so we can test an update function call\n",
    "                if choice > 1 and run_instance.memories:\n",
    "                    # Select a random memory to mutate\n",
    "                    selected_memory = random.choice(run_instance.memories)\n",
    "\n",
    "                    # Find the index of the selected memory\n",
    "                    index = run_instance.memories.index(selected_memory)\n",
    "\n",
    "                    mutated_memory = mutate_memory_runnable.invoke({\"memory\": selected_memory})\n",
    "\n",
    "                    # Replace the selected memory with the mutated memory\n",
    "                    run_instance.memories[index] = mutated_memory.content\n",
    "            elif choice == 3:\n",
    "                # No memory\n",
    "                run_instance = Run(input=data.get(\"input\"))\n",
    "                run_instance.update_memories(\"\")\n",
    "            else:\n",
    "                # Grab and join inputs from 1 or 2 other entries\n",
    "                other_entries = random.sample(data_entries[:index], random.randint(1, 2))\n",
    "                combined_input = \" \".join(\n",
    "                    [entry.get(\"input\", \"\") for entry in other_entries]\n",
    "                )\n",
    "                messages = [HumanMessage(content=combined_input)]\n",
    "                response = knowledge_master_runnable.invoke(\n",
    "                    {\"messages\": messages, \"memories\": []}\n",
    "                )\n",
    "                run_instance = Run(input=data.get(\"input\"))\n",
    "                run_instance.update_memories(response.additional_kwargs)\n",
    "\n",
    "            updated_runs.append(run_instance.to_dict())\n",
    "\n",
    "    # Rewrite the updated runs back to the file\n",
    "    with open(file_name, \"w\") as outfile:\n",
    "        for run in updated_runs:\n",
    "            json.dump(run, outfile)\n",
    "            outfile.write(\"\\n\")\n",
    "\n",
    "    print(f\"Updated {len(updated_runs)} runs in {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated 10 runs in eval_dataset.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "generate_memories_for_eval_dataset(EVAL_FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Generate expected output based on inputs and memories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated 10 runs in eval_dataset.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Loop through each row and generate an expected output with the runnable we have already defined to generate memories\n",
    "\n",
    "import json\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "\n",
    "def generate_expected_output_for_eval_dataset(file_name):\n",
    "    updated_runs = []\n",
    "\n",
    "    with open(file_name, \"r\") as infile:\n",
    "        for line in infile:\n",
    "            data = json.loads(line.strip())\n",
    "            if \"input\" in data:\n",
    "                messages = [HumanMessage(content=data.get(\"input\"))]\n",
    "                memories = data.get(\"memories\", [])\n",
    "                # Invoke the knowledge_master_runnable with the current input\n",
    "                response = knowledge_master_runnable.invoke(\n",
    "                    {\"messages\": messages, \"memories\": memories}\n",
    "                )\n",
    "\n",
    "                # Create a Run instance and update the expected output\n",
    "                run_instance = Run(\n",
    "                    input=data.get(\"input\"),\n",
    "                    memories=memories,\n",
    "                )\n",
    "\n",
    "                run_instance.update_desired_response(response.additional_kwargs)\n",
    "\n",
    "                updated_runs.append(run_instance.to_dict())\n",
    "\n",
    "    # Rewrite the updated runs back to the file\n",
    "    with open(file_name, \"w\") as outfile:\n",
    "        for run in updated_runs:\n",
    "            json.dump(run, outfile)\n",
    "            outfile.write(\"\\n\")\n",
    "\n",
    "    print(f\"Updated {len(updated_runs)} runs in {file_name}\")\n",
    "\n",
    "\n",
    "# Usage\n",
    "generate_expected_output_for_eval_dataset(EVAL_FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 - Generate the bad output based on our expected outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a chain to subtly mutate our desired output\n",
    "\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "SYSTEM_TEMPLATE_MUTATE_RESPONSE = \"\"\"\n",
    "Your job is to mutate a string of text to subtly change the meaning of it by only changing or modifying a single word.\n",
    "\n",
    "This may take a few possible paths:\n",
    "- You might make the meaning the opposite of the original meaning\n",
    "- You might change the subject to be something different\n",
    "- You might modify the verb to make it stronger, weaker, or completely different\n",
    "- You might change the complement to be something different\n",
    "\n",
    "The end sentence should still make sense, it should just be a different sentence with different original meaning than the original because of the word you changed.\n",
    "\n",
    "Here is the sentence to modify: \n",
    "\n",
    "```\n",
    "{desired_response}\n",
    "```\n",
    "\n",
    "Now return a string that contains the modified sentence and nothing else.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Get the prompt to use - you can modify this!\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessagePromptTemplate.from_template(SYSTEM_TEMPLATE_MUTATE_RESPONSE),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Choose the LLM that will drive the agent\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo-0125\",\n",
    "    temperature=0.4,\n",
    ")\n",
    "\n",
    "mutation_runnable = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated 10 bad responses in eval_dataset.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Iterate through each row and generate a bad output\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "def generate_bad_output_for_eval_dataset(file_name):\n",
    "    updated_runs = []\n",
    "\n",
    "    with open(file_name, \"r\") as infile:\n",
    "        for line in infile:\n",
    "            data = json.loads(line.strip())\n",
    "            if \"desired_response\" in data:\n",
    "                bad_responses = deepcopy(\n",
    "                    data[\"desired_response\"]\n",
    "                )\n",
    "\n",
    "                for response in bad_responses:\n",
    "                    choice = random.randint(1, 4)\n",
    "                    # We either want to:\n",
    "                    # 1. Change the content of category to a different one\n",
    "                    # 2. Change the action to a different one\n",
    "                    # 3. Mutate the contents of knowledge\n",
    "\n",
    "                    if choice == 1:\n",
    "                        # Change the content of category to a different one\n",
    "                        current_category = Category(response.get(\"category\", \"\"))\n",
    "                        all_categories = [c for c in Category if c != current_category]\n",
    "                        response[\"category\"] = random.choice(all_categories).value\n",
    "\n",
    "                    elif choice == 2:\n",
    "                        # Change the action to a different one\n",
    "                        current_action = Action(response.get(\"action\", \"\"))\n",
    "                        all_actions = [a for a in Action if a != current_action]\n",
    "                        response[\"action\"] = random.choice(all_actions).value\n",
    "\n",
    "                    else:\n",
    "                        # Mutate the contents of knowledge\n",
    "                        inference = mutation_runnable.invoke(\n",
    "                            {\"desired_response\": response.get(\"knowledge\", \"\")}\n",
    "                        )\n",
    "                        response[\"knowledge\"] = inference.content\n",
    "\n",
    "                data[\"bad_response\"] = bad_responses\n",
    "                updated_runs.append(data)\n",
    "\n",
    "    # Rewrite the updated runs back to the file\n",
    "    with open(file_name, \"w\") as outfile:\n",
    "        for run in updated_runs:\n",
    "            json.dump(run, outfile)\n",
    "            outfile.write(\"\\n\")\n",
    "\n",
    "    print(f\"Updated {len(updated_runs)} bad responses in {file_name}\")\n",
    "\n",
    "\n",
    "# Usage\n",
    "generate_bad_output_for_eval_dataset(EVAL_FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 - Generate Fine-tuning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def generate_data_for_finetuning(input_file_name, output_file_name):\n",
    "    with open(input_file_name, \"r\") as infile, open(output_file_name, \"w\") as outfile:\n",
    "        for line in infile:\n",
    "            data = json.loads(line.strip())\n",
    "\n",
    "            # Extract user content and assistant message\n",
    "            user_content = data.get(\"input\", \"\")  # Replace with actual key\n",
    "            assistant_message = data.get(\n",
    "                \"desired_assistant_message\", \"\"\n",
    "            )  # Replace with actual key\n",
    "\n",
    "            # Create new record\n",
    "            new_record = {\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"user\", \"content\": user_content},\n",
    "                    assistant_message,\n",
    "                ],\n",
    "                \"functions\": [\n",
    "                    {\n",
    "                        \"name\": \"Knowledge_Modifier\",\n",
    "                        \"description\": \"Knowledge_Modifier(knowledge: str, category: str, action: str, knowledge_old: str = '') -> dict - Add, update, or delete a bit of knowledge\",\n",
    "                        \"parameters\": {\n",
    "                            \"type\": \"object\",\n",
    "                            \"properties\": {\n",
    "                                \"knowledge\": {\n",
    "                                    \"description\": \"Condensed bit of knowledge to be saved for future reference in the format [person] [fact] (e.g. Husband doesn't like tuna, I am allergic to shellfish, etc)\",\n",
    "                                    \"type\": \"string\",\n",
    "                                },\n",
    "                                \"knowledge_old\": {\n",
    "                                    \"description\": \"If updating or deleting record, the complete, exact phrase that needs to be modified\",\n",
    "                                    \"type\": \"string\",\n",
    "                                },\n",
    "                                \"category\": {\n",
    "                                    \"description\": \"Category that this knowledge belongs to\",\n",
    "                                    \"allOf\": [\n",
    "                                        {\n",
    "                                            \"title\": \"Category\",\n",
    "                                            \"description\": \"An enumeration.\",\n",
    "                                            \"enum\": [\n",
    "                                                \"Allergy\",\n",
    "                                                \"Like\",\n",
    "                                                \"Dislike\",\n",
    "                                                \"Attribute\",\n",
    "                                            ],\n",
    "                                            \"type\": \"string\",\n",
    "                                        }\n",
    "                                    ],\n",
    "                                },\n",
    "                                \"action\": {\n",
    "                                    \"description\": \"Whether this knowledge is adding a new record, updating a record, or deleting a record\",\n",
    "                                    \"allOf\": [\n",
    "                                        {\n",
    "                                            \"title\": \"Action\",\n",
    "                                            \"description\": \"An enumeration.\",\n",
    "                                            \"enum\": [\"Create\", \"Update\", \"Delete\"],\n",
    "                                            \"type\": \"string\",\n",
    "                                        }\n",
    "                                    ],\n",
    "                                },\n",
    "                            },\n",
    "                            \"required\": [\"knowledge\", \"category\", \"action\"],\n",
    "                        },\n",
    "                    }\n",
    "                ],\n",
    "            }\n",
    "\n",
    "            # Write new record to output file\n",
    "            json.dump(new_record, outfile)\n",
    "            outfile.write(\"\\n\")\n",
    "\n",
    "\n",
    "# Usage\n",
    "generate_data_for_finetuning(EVAL_FILE_PATH, FINETUNE_FILE_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

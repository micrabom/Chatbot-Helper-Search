{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Long-Term Memory from a Conversation\n",
    "This Notebook shows how to set up an agent that can extract memories from a conversation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install openai==1.12.0 langchain==0.1.6 langchain_openai==0.0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Set model variables\n",
    "OPENAI_BASE_URL = \"https://api.openai.com/v1\"\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "OPENAI_ORGANIZATION = os.getenv(\"OPENAI_ORGANIZATION\")\n",
    "\n",
    "# Initialize LangSmith\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"Demos\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Agent: Memory Sentinel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    ")\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "\n",
    "system_prompt_initial = \"\"\"\n",
    "Your job is to assess a brief chat history in order to determine if the conversation contains any details about a family's dining habits. \n",
    "\n",
    "You are part of a team building a knowledge base regarding a family's dining habits to assist in highly customized meal planning.\n",
    "\n",
    "You play the critical role of assessing the message to determine if it contains any information worth recording in the knowledge base.\n",
    "\n",
    "You are only interested in the following categories of information:\n",
    "\n",
    "1. The family's food allergies (e.g. a dairy or soy allergy)\n",
    "2. Foods the family likes (e.g. likes pasta)\n",
    "3. Foods the family dislikes (e.g. doesn't eat mussels)\n",
    "4. Attributes about the family that may impact weekly meal planning (e.g. lives in Austin; has a husband and 2 children; has a garden; likes big lunches; etc.)\n",
    "\n",
    "When you receive a message, you perform a sequence of steps consisting of:\n",
    "\n",
    "1. Analyze the message for information.\n",
    "2. If it has any information worth recording, return TRUE. If not, return FALSE.\n",
    "\n",
    "You should ONLY RESPOND WITH TRUE OR FALSE. Absolutely no other information should be provided.\n",
    "\n",
    "Take a deep breath, think step by step, and then analyze the following message:\n",
    "\"\"\"\n",
    "\n",
    "# Get the prompt to use - you can modify this!\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessagePromptTemplate.from_template(system_prompt_initial),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Remember, only respond with TRUE or FALSE. Do not provide any other information.\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Choose the LLM that will drive the agent\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo-0125\",\n",
    "    streaming=True,\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "sentinel_runnable = {\"messages\": RunnablePassthrough()} | prompt | llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Agent: Memory Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langchain.tools import StructuredTool\n",
    "from enum import Enum\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "class Category(str, Enum):\n",
    "    Food_Allergy = \"Allergy\"\n",
    "    Food_Like = \"Like\"\n",
    "    Food_Dislike = \"Dislike\"\n",
    "    Family_Attribute = \"Attribute\"\n",
    "\n",
    "\n",
    "class Action(str, Enum):\n",
    "    Create = \"Create\"\n",
    "    Update = \"Update\"\n",
    "    Delete = \"Delete\"\n",
    "\n",
    "\n",
    "class AddKnowledge(BaseModel):\n",
    "    knowledge: str = Field(\n",
    "        ...,\n",
    "        description=\"Condensed bit of knowledge to be saved for future reference in the format: [person(s) this is relevant to] [fact to store] (e.g. Husband doesn't like tuna; I am allergic to shellfish; etc)\",\n",
    "    )\n",
    "    knowledge_old: Optional[str] = Field(\n",
    "        None,\n",
    "        description=\"If updating or deleting record, the complete, exact phrase that needs to be modified\",\n",
    "    )\n",
    "    category: Category = Field(\n",
    "        ..., description=\"Category that this knowledge belongs to\"\n",
    "    )\n",
    "    action: Action = Field(\n",
    "        ...,\n",
    "        description=\"Whether this knowledge is adding a new record, updating a record, or deleting a record\",\n",
    "    )\n",
    "\n",
    "\n",
    "def modify_knowledge(\n",
    "    knowledge: str,\n",
    "    category: str,\n",
    "    action: str,\n",
    "    knowledge_old: str = \"\",\n",
    ") -> dict:\n",
    "    print(\"Modifying Knowledge: \", knowledge, knowledge_old, category, action)\n",
    "    return \"Modified Knowledge\"\n",
    "\n",
    "\n",
    "tool_modify_knowledge = StructuredTool.from_function(\n",
    "    func=modify_knowledge,\n",
    "    name=\"Knowledge_Modifier\",\n",
    "    description=\"Add, update, or delete a bit of knowledge\",\n",
    "    args_schema=AddKnowledge,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the tools to execute them from the graph\n",
    "from langgraph.prebuilt import ToolExecutor\n",
    "\n",
    "# Set up the agent's tools\n",
    "agent_tools = [tool_modify_knowledge]\n",
    "\n",
    "tool_executor = ToolExecutor(agent_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    ")\n",
    "from langchain_core.utils.function_calling import convert_to_openai_function\n",
    "\n",
    "system_prompt_initial = \"\"\"\n",
    "You are a supervisor managing a team of knowledge eperts.\n",
    "\n",
    "Your team's job is to create a perfect knowledge base about a family's dining habits to assist in highly customized meal planning.\n",
    "\n",
    "The knowledge base should ultimately consist of many discrete pieces of information that add up to a rich persona (e.g. I like pasta; I am allergic to shellfish; I don't eat mussels; I live in Austin, Texas; I have a husband and 2 children aged 5 and 7).\n",
    "\n",
    "Every time you receive a message, you will evaluate if it has any information worth recording in the knowledge base.\n",
    "\n",
    "A message may contain multiple pieces of information that should be saved separately.\n",
    "\n",
    "You are only interested in the following categories of information:\n",
    "\n",
    "1. The family's food allergies (e.g. a dairy or soy allergy) - These are important to know because they can be life-threatening. Only log something as an allergy if you are certain it is an allergy and not just a dislike.\n",
    "2. Foods the family likes (e.g. likes pasta) - These are important to know because they can help you plan meals, but are not life-threatening.\n",
    "3. Foods the family dislikes (e.g. doesn't eat mussels or rarely eats beef) - These are important to know because they can help you plan meals, but are not life-threatening.\n",
    "4. Attributes about the family that may impact weekly meal planning (e.g. lives in Austin; has a husband and 2 children; has a garden; likes big lunches, etc.)\n",
    "\n",
    "When you receive a message, you perform a sequence of steps consisting of:\n",
    "\n",
    "1. Analyze the most recent Human message for information. You will see multiple messages for context, but we are only looking for new information in the most recent message.\n",
    "2. Compare this to the knowledge you already have.\n",
    "3. Determine if this is new knowledge, an update to old knowledge that now needs to change, or should result in deleting information that is not correct. It's possible that a food you previously wrote as a dislike might now be a like, or that a family member who previously liked a food now dislikes it - those examples would require an update.\n",
    "\n",
    "Here are the existing bits of information that we have about the family.\n",
    "\n",
    "```\n",
    "{memories}\n",
    "```\n",
    "\n",
    "Call the right tools to save the information, then respond with DONE. If you identiy multiple pieces of information, call everything at once. You only have one chance to call tools.\n",
    "\n",
    "I will tip you $20 if you are perfect, and I will fine you $40 if you miss any important information or change any incorrect information.\n",
    "\n",
    "Take a deep breath, think step by step, and then analyze the following message:\n",
    "\"\"\"\n",
    "\n",
    "# Get the prompt to use - you can modify this!\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessagePromptTemplate.from_template(system_prompt_initial),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Choose the LLM that will drive the agent\n",
    "llm = ChatOpenAI(\n",
    "    # model=\"gpt-3.5-turbo-0125\",\n",
    "    model=\"gpt-4-0125-preview\",\n",
    "    streaming=True,\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "# Create the tools to bind to the model\n",
    "tools = [convert_to_openai_function(t) for t in agent_tools]\n",
    "\n",
    "knowledge_master_runnable = prompt | llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Sequence\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    # The list of previous messages in the conversation\n",
    "    messages: Sequence[BaseMessage]\n",
    "    # The long-term memories to remember\n",
    "    memories: Sequence[str]\n",
    "    # Whether the information is relevant\n",
    "    contains_information: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain_core.messages import ToolMessage\n",
    "from langgraph.prebuilt import ToolInvocation\n",
    "\n",
    "\n",
    "def call_sentinel(state):\n",
    "    messages = state[\"messages\"]\n",
    "    response = sentinel_runnable.invoke(messages)\n",
    "    return {\"contains_information\": \"TRUE\" in response.content and \"yes\" or \"no\"}\n",
    "\n",
    "\n",
    "# Define the function that determines whether to continue or not\n",
    "def should_continue(state):\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    # If there are no tool calls, then we finish\n",
    "    if \"tool_calls\" not in last_message.additional_kwargs:\n",
    "        return \"end\"\n",
    "    # Otherwise, we continue\n",
    "    else:\n",
    "        return \"continue\"\n",
    "\n",
    "\n",
    "# Define the function that calls the knowledge master\n",
    "def call_knowledge_master(state):\n",
    "    messages = state[\"messages\"]\n",
    "    memories = state[\"memories\"]\n",
    "    response = knowledge_master_runnable.invoke(\n",
    "        {\"messages\": messages, \"memories\": memories}\n",
    "    )\n",
    "    return {\"messages\": messages + [response]}\n",
    "\n",
    "\n",
    "# Define the function to execute tools\n",
    "def call_tool(state):\n",
    "    messages = state[\"messages\"]\n",
    "    # We know the last message involves at least one tool call\n",
    "    last_message = messages[-1]\n",
    "\n",
    "    # We loop through all tool calls and append the message to our message log\n",
    "    for tool_call in last_message.additional_kwargs[\"tool_calls\"]:\n",
    "        action = ToolInvocation(\n",
    "            tool=tool_call[\"function\"][\"name\"],\n",
    "            tool_input=json.loads(tool_call[\"function\"][\"arguments\"]),\n",
    "            id=tool_call[\"id\"],\n",
    "        )\n",
    "\n",
    "        # We call the tool_executor and get back a response\n",
    "        response = tool_executor.invoke(action)\n",
    "        # We use the response to create a FunctionMessage\n",
    "        function_message = ToolMessage(\n",
    "            content=str(response), name=action.tool, tool_call_id=tool_call[\"id\"]\n",
    "        )\n",
    "\n",
    "        # Add the function message to the list\n",
    "        messages.append(function_message)\n",
    "    return {\"messages\": messages}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# Initialize a new graph\n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "# Define the two \"Nodes\"\" we will cycle between\n",
    "graph.add_node(\"sentinel\", call_sentinel)\n",
    "graph.add_node(\"knowledge_master\", call_knowledge_master)\n",
    "graph.add_node(\"action\", call_tool)\n",
    "\n",
    "# Define all our Edges\n",
    "\n",
    "# Set the Starting Edge\n",
    "graph.set_entry_point(\"sentinel\")\n",
    "\n",
    "# We now add Conditional Edges\n",
    "graph.add_conditional_edges(\n",
    "    \"sentinel\",\n",
    "    lambda x: x[\"contains_information\"],\n",
    "    {\n",
    "        \"yes\": \"knowledge_master\",\n",
    "        \"no\": END,\n",
    "    },\n",
    ")\n",
    "graph.add_conditional_edges(\n",
    "    \"knowledge_master\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"continue\": \"action\",\n",
    "        \"end\": END,\n",
    "    },\n",
    ")\n",
    "\n",
    "# We now add Normal Edges that should always be called after another\n",
    "graph.add_edge(\"action\", END)\n",
    "\n",
    "# We compile the entire workflow as a runnable\n",
    "app = graph.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run our Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "message = \"There are 6 people in my family. My wife doesn't eat meat and my youngest daughter is allergic to dairy.\"\n",
    "\n",
    "inputs = {\n",
    "    \"messages\": [HumanMessage(content=message)],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from node 'sentinel':\n",
      "---\n",
      "{'contains_information': 'yes'}\n",
      "\n",
      "---\n",
      "\n",
      "Output from node 'knowledge_master':\n",
      "---\n",
      "{'messages': [HumanMessage(content=\"There are 6 people in my family. My wife doesn't eat meat and my youngest daughter is allergic to dairy.\"), AIMessage(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_N3OUsTB9UNxI6JF2A6AggH4z', 'function': {'arguments': '{\"knowledge\": \"Family consists of 6 people\", \"category\": \"Attribute\", \"action\": \"Create\"}', 'name': 'Knowledge_Modifier'}, 'type': 'function'}, {'index': 1, 'id': 'call_UJz5NaecIpxiwAwlODdUgabA', 'function': {'arguments': '{\"knowledge\": \"Wife doesn\\'t eat meat\", \"category\": \"Dislike\", \"action\": \"Create\"}', 'name': 'Knowledge_Modifier'}, 'type': 'function'}, {'index': 2, 'id': 'call_6fnDlpEdBFTgCPBwFISZdXDY', 'function': {'arguments': '{\"knowledge\": \"Youngest daughter is allergic to dairy\", \"category\": \"Allergy\", \"action\": \"Create\"}', 'name': 'Knowledge_Modifier'}, 'type': 'function'}]})]}\n",
      "\n",
      "---\n",
      "\n",
      "Modifying Knowledge:  Family consists of 6 people  Category.Family_Attribute Action.Create\n",
      "Modifying Knowledge:  Wife doesn't eat meat  Category.Food_Dislike Action.Create\n",
      "Modifying Knowledge:  Youngest daughter is allergic to dairy  Category.Food_Allergy Action.Create\n",
      "Output from node 'action':\n",
      "---\n",
      "{'messages': [HumanMessage(content=\"There are 6 people in my family. My wife doesn't eat meat and my youngest daughter is allergic to dairy.\"), AIMessage(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_N3OUsTB9UNxI6JF2A6AggH4z', 'function': {'arguments': '{\"knowledge\": \"Family consists of 6 people\", \"category\": \"Attribute\", \"action\": \"Create\"}', 'name': 'Knowledge_Modifier'}, 'type': 'function'}, {'index': 1, 'id': 'call_UJz5NaecIpxiwAwlODdUgabA', 'function': {'arguments': '{\"knowledge\": \"Wife doesn\\'t eat meat\", \"category\": \"Dislike\", \"action\": \"Create\"}', 'name': 'Knowledge_Modifier'}, 'type': 'function'}, {'index': 2, 'id': 'call_6fnDlpEdBFTgCPBwFISZdXDY', 'function': {'arguments': '{\"knowledge\": \"Youngest daughter is allergic to dairy\", \"category\": \"Allergy\", \"action\": \"Create\"}', 'name': 'Knowledge_Modifier'}, 'type': 'function'}]}), ToolMessage(content='Modified Knowledge', tool_call_id='call_N3OUsTB9UNxI6JF2A6AggH4z', name='Knowledge_Modifier'), ToolMessage(content='Modified Knowledge', tool_call_id='call_UJz5NaecIpxiwAwlODdUgabA', name='Knowledge_Modifier'), ToolMessage(content='Modified Knowledge', tool_call_id='call_6fnDlpEdBFTgCPBwFISZdXDY', name='Knowledge_Modifier')]}\n",
      "\n",
      "---\n",
      "\n",
      "Output from node '__end__':\n",
      "---\n",
      "{'messages': [HumanMessage(content=\"There are 6 people in my family. My wife doesn't eat meat and my youngest daughter is allergic to dairy.\"), AIMessage(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_N3OUsTB9UNxI6JF2A6AggH4z', 'function': {'arguments': '{\"knowledge\": \"Family consists of 6 people\", \"category\": \"Attribute\", \"action\": \"Create\"}', 'name': 'Knowledge_Modifier'}, 'type': 'function'}, {'index': 1, 'id': 'call_UJz5NaecIpxiwAwlODdUgabA', 'function': {'arguments': '{\"knowledge\": \"Wife doesn\\'t eat meat\", \"category\": \"Dislike\", \"action\": \"Create\"}', 'name': 'Knowledge_Modifier'}, 'type': 'function'}, {'index': 2, 'id': 'call_6fnDlpEdBFTgCPBwFISZdXDY', 'function': {'arguments': '{\"knowledge\": \"Youngest daughter is allergic to dairy\", \"category\": \"Allergy\", \"action\": \"Create\"}', 'name': 'Knowledge_Modifier'}, 'type': 'function'}]}), ToolMessage(content='Modified Knowledge', tool_call_id='call_N3OUsTB9UNxI6JF2A6AggH4z', name='Knowledge_Modifier'), ToolMessage(content='Modified Knowledge', tool_call_id='call_UJz5NaecIpxiwAwlODdUgabA', name='Knowledge_Modifier'), ToolMessage(content='Modified Knowledge', tool_call_id='call_6fnDlpEdBFTgCPBwFISZdXDY', name='Knowledge_Modifier')], 'memories': None, 'contains_information': 'yes'}\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for output in app.with_config({\"run_name\": \"Memory\"}).stream(inputs):\n",
    "    # stream() yields dictionaries with output keyed by node name\n",
    "    for key, value in output.items():\n",
    "        print(f\"Output from node '{key}':\")\n",
    "        print(\"---\")\n",
    "        print(value)\n",
    "    print(\"\\n---\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

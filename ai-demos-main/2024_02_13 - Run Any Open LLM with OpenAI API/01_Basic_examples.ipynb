{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilizing Open LLMs with the OpenAI API\n",
    "This Notebook uses the same basic OpenAI Python API to run different local and serverless models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install openai==1.12.0 langchain==0.1.6 langchain_openai==0.0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Set model variables\n",
    "OPENAI_BASE_URL = \"https://api.openai.com/v1\"\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "OPENAI_ORGANIZATION = os.getenv(\"OPENAI_ORGANIZATION\")\n",
    "\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434/v1\"\n",
    "OLLAMA_API_KEY = \"ollama\"\n",
    "\n",
    "TOGETHER_BASE_URL = \"https://api.together.xyz\"\n",
    "TOGETHER_API_KEY = os.getenv(\"TOGETHER_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize tools and models for all demos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOOLS = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"Get the current weather\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                    },\n",
    "                    \"format\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                        \"description\": \"The temperature unit to use. Infer this from the users location.\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"location\", \"format\"],\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "]\n",
    "\n",
    "MESSAGES = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a helpful assistant that can access external functions. Please provide responses based on the information from these function calls.\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What is the current temperature of New York, San Francisco and Chicago?\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run a serverless Mixtral with the OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"id\": \"call_aohq18yhi3yav8p7z81jyjhw\",\n",
      "    \"function\": {\n",
      "      \"arguments\": \"{\\\"location\\\":\\\"New York, NY\\\",\\\"format\\\":\\\"fahrenheit\\\"}\",\n",
      "      \"name\": \"get_current_weather\"\n",
      "    },\n",
      "    \"type\": \"function\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"call_2wbb93smogfhtoiq5gcac2pw\",\n",
      "    \"function\": {\n",
      "      \"arguments\": \"{\\\"location\\\":\\\"San Francisco, CA\\\",\\\"format\\\":\\\"fahrenheit\\\"}\",\n",
      "      \"name\": \"get_current_weather\"\n",
      "    },\n",
      "    \"type\": \"function\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"call_3zkezuh2293wzjjiqwn1g63d\",\n",
      "    \"function\": {\n",
      "      \"arguments\": \"{\\\"location\\\":\\\"Chicago, IL\\\",\\\"format\\\":\\\"fahrenheit\\\"}\",\n",
      "      \"name\": \"get_current_weather\"\n",
      "    },\n",
      "    \"type\": \"function\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=TOGETHER_BASE_URL,\n",
    "    api_key=TOGETHER_API_KEY,\n",
    ")\n",
    "\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
    "    messages=MESSAGES,\n",
    "    tools=TOOLS,\n",
    "    tool_choice=\"auto\",\n",
    ")\n",
    "\n",
    "print(json.dumps(response.choices[0].message.model_dump()[\"tool_calls\"], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You can even stream responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\n",
      "  {\n",
      "    \"name\": \"get_current_weather\",\n",
      "    \"arguments\": {\n",
      "      \"location\": \"New York, NY\",\n",
      "      \"format\": \"fahrenheit\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"name\": \"get_current_weather\",\n",
      "    \"arguments\": {\n",
      "      \"location\": \"San Francisco, CA\",\n",
      "      \"format\": \"fahrenheit\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"name\": \"get_current_weather\",\n",
      "    \"arguments\": {\n",
      "      \"location\": \"Chicago, IL\",\n",
      "      \"format\": \"fahrenheit\"\n",
      "    }\n",
      "  }\n",
      "]"
     ]
    }
   ],
   "source": [
    "stream = client.chat.completions.create(\n",
    "    model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
    "    messages=MESSAGES,\n",
    "    stream=True,\n",
    "    tools=TOOLS,\n",
    "    tool_choice=\"auto\",\n",
    ")\n",
    "\n",
    "for chunk in stream:\n",
    "    print(chunk.choices[0].delta.content or \"\", end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run 5 different models with the same API: 2 Serverless, 2 Local, 1 OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CONFIGS = [\n",
    "    {\n",
    "        \"description\": \"Llama2 Locally\",\n",
    "        \"base_url\": OLLAMA_BASE_URL,\n",
    "        \"api_key\": OLLAMA_API_KEY,\n",
    "        \"model\": \"llama2\",\n",
    "    },\n",
    "    {\n",
    "        \"description\": \"Mistral Locally\",\n",
    "        \"base_url\": OLLAMA_BASE_URL,\n",
    "        \"api_key\": OLLAMA_API_KEY,\n",
    "        \"model\": \"mistral\",\n",
    "    },\n",
    "    {\n",
    "        \"description\": \"Llama2 Serverless\",\n",
    "        \"base_url\": TOGETHER_BASE_URL,\n",
    "        \"api_key\": TOGETHER_API_KEY,\n",
    "        \"model\": \"togethercomputer/llama-2-13b-chat\",\n",
    "    },\n",
    "    {\n",
    "        \"description\": \"Mixtral Serverless\",\n",
    "        \"base_url\": TOGETHER_BASE_URL,\n",
    "        \"api_key\": TOGETHER_API_KEY,\n",
    "        \"model\": \"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
    "    },\n",
    "    {\n",
    "        \"description\": \"OpenAI Serverless\",\n",
    "        \"base_url\": OPENAI_BASE_URL,\n",
    "        \"api_key\": OPENAI_API_KEY,\n",
    "        \"model\": \"gpt-3.5-turbo-1106\",\n",
    "    },\n",
    "]\n",
    "\n",
    "MESSAGES_FOR_POEMS = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a poet who writes whimsical haikus about a given topic.\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Topic: Ducks\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Llama2 Locally:\n",
      "-----------------------------\n",
      "\n",
      "Quacking in the pond,\n",
      "Feathers fluffed, beaks dipped,\n",
      "Ducks swim and play.\n",
      "\n",
      "Ribbons of blue and gold,\n",
      "Flapping wings, a gentle sight,\n",
      "Ducks take flight.\n",
      "\n",
      "In the sun or rain,\n",
      "Quacking ducks bring joy again,\n",
      "Waterfowl delight.\n",
      "\n",
      "Splashes in the water,\n",
      "Feathers flung, a ducky dance,\n",
      "Happiness abounds.\n",
      "\n",
      "\n",
      "Running Mistral Locally:\n",
      "-----------------------------\n",
      "\n",
      " Quiet pond reflects,\n",
      "Beneath, ducks weave graceful patterns,\n",
      "Nature's art unfolds.\n",
      "\n",
      "Dancing in the rain,\n",
      "Ducks splash and play, pure joy abounds,\n",
      "Life's simple pleasures.\n",
      "\n",
      "Morning sun illumines,\n",
      "Feathered friends paddle calmly by,\n",
      "Serenity reigns.\n",
      "\n",
      "Beneath the autumn sky,\n",
      "Ducks align in perfect rows,\n",
      "Autumn's graceful grace.\n",
      "\n",
      "\n",
      "Running Llama2 Serverless:\n",
      "-----------------------------\n",
      "\n",
      " Quacking in the pond,\n",
      "Feathers fluffed and shining bright,\n",
      "Ducks dance in the sun.\n",
      "\n",
      "\n",
      "Running Mixtral Serverless:\n",
      "-----------------------------\n",
      "\n",
      "Feathers, bright and dappled,\n",
      "Water's surface, gently broken,\n",
      "Ducks, a dance of joy.\n",
      "\n",
      "In the pond, they play,\n",
      "Quacking tales of wind and rain,\n",
      "Ducks, in rhythm, sway.\n",
      "\n",
      "Sunset's glow, so soft,\n",
      "Ducks, in twilight, tuck away,\n",
      "Dreams of flight take hold.\n",
      "\n",
      "\n",
      "Running OpenAI Serverless:\n",
      "-----------------------------\n",
      "\n",
      "Majestic mallards\n",
      "Gliding on the tranquil pond\n",
      "Quacking with delight\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in MODEL_CONFIGS:\n",
    "\n",
    "    print(f\"Running {model['description']}:\")\n",
    "    print(f\"-----------------------------\\n\")\n",
    "\n",
    "    client = OpenAI(\n",
    "        base_url=model[\"base_url\"],\n",
    "        api_key=model[\"api_key\"],\n",
    "    )\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model[\"model\"],\n",
    "        messages=MESSAGES_FOR_POEMS,\n",
    "    )\n",
    "\n",
    "    print(f\"{response.choices[0].message.content}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This also works well with LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Llama2 Locally:\n",
      "-----------------------------\n",
      "\n",
      "\n",
      "Quacking echoes flow\n",
      "Through the pond's reflective depths\n",
      "Ducks dance with grace\n",
      "\n",
      "\n",
      "Running Mistral Locally:\n",
      "-----------------------------\n",
      "\n",
      " Quilt of feathers swirl,\n",
      "River's mirror dances bright,\n",
      "Ducks paddle, twinkle, world.\n",
      "\n",
      "\n",
      "Running Llama2 Serverless:\n",
      "-----------------------------\n",
      "\n",
      " Sure! Here's a whimsical haiku about ducks:\n",
      "\n",
      "Quacking in the pond,\n",
      "Feathers fluffed and feisty,\n",
      "Ducks dance on water.\n",
      "\n",
      "\n",
      "Running Mixtral Serverless:\n",
      "-----------------------------\n",
      "\n",
      "Quacking in glee,\n",
      "Feathers of rainbow hues,\n",
      "Pond dance in delight.\n",
      "\n",
      "\n",
      "Running OpenAI Serverless:\n",
      "-----------------------------\n",
      "\n",
      "Feathers float and glide\n",
      "Quacking waddlers on the pond\n",
      "Ducks bring joy inside\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "for model in MODEL_CONFIGS:\n",
    "\n",
    "    print(f\"Running {model['description']}:\")\n",
    "    print(f\"-----------------------------\\n\")\n",
    "\n",
    "    llm = ChatOpenAI(\n",
    "        openai_api_base=model[\"base_url\"],\n",
    "        api_key=model[\"api_key\"],\n",
    "        model=model[\"model\"],\n",
    "        temperature=1.0,\n",
    "    )\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", \"Write a whimsical haiku about a given topic.\"),\n",
    "            (\"user\", \"Topic: Ducks\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    poem_runnable = prompt | llm\n",
    "\n",
    "    response = poem_runnable.invoke({})\n",
    "    print(f\"{response.content}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
